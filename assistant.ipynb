{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b053c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model_provider=\"ollama\",\n",
    "    model = \"llama3.2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3707f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageClassifier(BaseModel):\n",
    "    message_type: Literal[\"emotional\", \"logical\"] = Field(\n",
    "        ...,\n",
    "        description=\"Classify if the message requires an emotional (therapist) or logical response.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecfccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    message_type: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e9bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    classifier_llm = llm.with_structured_output(MessageClassifier)\n",
    "\n",
    "    result = classifier_llm.invoke([\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Classify the user message as either:\n",
    "            - 'emotional': if it asks for emotional support, therapy, deals with feelings, or personal problems\n",
    "            - 'logical': if it asks for facts, information, logical analysis, or practical solutions\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": last_message.content}\n",
    "    ])\n",
    "    return {\"message_type\": result.message_type}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1351a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: State):\n",
    "    message_type = state.get(\"message_type\", \"logical\")\n",
    "    if message_type == \"emotional\":\n",
    "        return {\"next\": \"therapist\"}\n",
    "\n",
    "    return {\"next\": \"logical\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a98288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def therapist_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"\"\"You are a compassionate therapist. Focus on the emotional aspects of the user's message.\n",
    "                        Show empathy, validate their feelings, and help them process their emotions.\n",
    "                        Ask thoughtful questions to help them explore their feelings more deeply.\n",
    "                        Avoid giving logical solutions unless explicitly asked.\"\"\"\n",
    "         },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": last_message.content\n",
    "        }\n",
    "    ]\n",
    "    reply = llm.invoke(messages)\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d089637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"\"\"You are a purely logical assistant. Focus only on facts and information.\n",
    "            Provide clear, concise answers based on logic and evidence.\n",
    "            Do not address emotions or provide emotional support.\n",
    "            Be direct and straightforward in your responses.\"\"\"\n",
    "         },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": last_message.content\n",
    "        }\n",
    "    ]\n",
    "    reply = llm.invoke(messages)\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838dd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
