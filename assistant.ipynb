{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b053c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model_provider=\"ollama\",\n",
    "    model = \"llama3.2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3707f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageClassifier(BaseModel):\n",
    "    message_type: Literal[\"emotional\", \"logical\"] = Field(\n",
    "        ...,\n",
    "        description=\"Classify if the message requires an emotional (therapist) or logical response.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecfccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    message_type: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e9bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    classifier_llm = llm.with_structured_output(MessageClassifier)\n",
    "\n",
    "    result = classifier_llm.invoke([\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Classify the user message as either:\n",
    "            - 'emotional': if it asks for emotional support, therapy, deals with feelings, or personal problems\n",
    "            - 'logical': if it asks for facts, information, logical analysis, or practical solutions\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": last_message.content}\n",
    "    ])\n",
    "    return {\"message_type\": result.message_type}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1351a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: State):\n",
    "    message_type = state.get(\"message_type\", \"logical\")\n",
    "    if message_type == \"emotional\":\n",
    "        return {\"next\": \"therapist\"}\n",
    "\n",
    "    return {\"next\": \"logical\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a98288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def therapist_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"\"\"You are a compassionate therapist. Focus on the emotional aspects of the user's message.\n",
    "                        Show empathy, validate their feelings, and help them process their emotions.\n",
    "                        Ask thoughtful questions to help them explore their feelings more deeply.\n",
    "                        Avoid giving logical solutions unless explicitly asked.\"\"\"\n",
    "         },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": last_message.content\n",
    "        }\n",
    "    ]\n",
    "    reply = llm.invoke(messages)\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d089637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"\"\"You are a purely logical assistant. Focus only on facts and information.\n",
    "            Provide clear, concise answers based on logic and evidence.\n",
    "            Do not address emotions or provide emotional support.\n",
    "            Be direct and straightforward in your responses.\"\"\"\n",
    "         },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": last_message.content\n",
    "        }\n",
    "    ]\n",
    "    reply = llm.invoke(messages)\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": reply.content}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8838dd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x19358dd4c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"classifier\", classify_message)\n",
    "graph_builder.add_node(\"router\", router)\n",
    "graph_builder.add_node(\"therapist\", therapist_agent)\n",
    "graph_builder.add_node(\"logical\", logical_agent)\n",
    "\n",
    "graph_builder.add_edge(START, \"classifier\")\n",
    "graph_builder.add_edge(\"classifier\", \"router\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d88452",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda state: state.get(\"next\"),\n",
    "    {\"therapist\": \"therapist\", \"logical\": \"logical\"}\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"therapist\", END)\n",
    "graph_builder.add_edge(\"logical\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aaf85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chatbot():\n",
    "    state = {\"messages\": [], \"message_type\": None}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Message: \")\n",
    "        if user_input == \"exit\":\n",
    "            print(\"Bye\")\n",
    "            break\n",
    "\n",
    "        state[\"messages\"] = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "\n",
    "        state = graph.invoke(state)\n",
    "\n",
    "        if state.get(\"messages\") and len(state[\"messages\"]) > 0:\n",
    "            last_message = state[\"messages\"][-1]\n",
    "            print(f\"Assistant: {last_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880497df",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329a61f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
